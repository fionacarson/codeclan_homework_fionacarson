train_resid <- train %>%
add_residuals(mod3) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar)
#ggpairs(train_resid, progress = FALSE)
mod4 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide, train)
summary(mod4)
anova(mod3, mod4)
train_resid <- train %>%
add_residuals(mod4) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide)
#ggpairs(train_resid, progress = FALSE)
mod5 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity, train)
summary(mod5)
AIC(mod3, mod4, mod5)
BIC(mod3, mod4, mod5)
train_resid <- train %>%
add_residuals(mod5) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide, -fixed_acidity)
#ggpairs(train_resid, progress = FALSE)
mod6 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity + sulphates, train)
summary(mod6)
AIC(mod5, mod6)
BIC(mod5, mod6)
train_resid <- train %>%
add_residuals(mod6) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide, -fixed_acidity, -sulphates)
#ggpairs(train_resid, progress = FALSE)
#autoplot(mod6)
#plot(mod6)
train %>%
ggplot(aes(quality2, sulphates, colour = residual_sugar)) +
geom_point() +
geom_smooth(method = "lm")
coplot(quality2 ~ residual_sugar | sulphates,
overlap = FALSE,
panel = function(x, y, ...){
points(x, y)
abline(lm(y ~ x), col = "blue")
},
data = train, rows = 1)
train %>%
ggplot(aes(x = quality2, y = alcohol, colour = region)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
mod7 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity + sulphates +
residual_sugar : volatile_acidity, train)
summary(mod7)
anova(mod6, mod7)
prediction <- predict(mod7, test)
output <- cbind(test, prediction)
output %>%
ggplot(aes(quality2, prediction)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, colour = "red")
relaimpo::calc.relimp(mod7, type = "lmg", rela = TRUE)
predictions_test <- test %>%
add_predictions(mod7) %>%
select(quality2, pred)
mse_test <- mean((predictions_test$pred - test$quality2)**2)
mse_test
predictions_train <- train %>%
add_predictions(mod7) %>%
select(quality2, pred)
mse_train <- mean((predictions_train$pred - train$quality2)**2)
mse_train
# remove quality and region variables before fitting glmulti
white_trim <- white %>%
select(-quality, -region)
train_index <- createDataPartition(white_trim$quality2, p = 0.8, list = FALSE, times = 1)
train_automated <- white_trim[train_index, ]
test_automated <- white_trim[-train_index,]
glmulti_fit <- glmulti(
quality2 ~ ., # model to fit, in this case, charges varies with everything
level = 2, # level = 2 means try pairwise interactions. level = 1 means main effects only
data = train_automated, # data to use for fitting
minsize = 0, # min size of model to try, in number of predictors
maxsize = -1, # max size to try, set to -1 for unlimited
marginality = TRUE, # marginality true means include pairwise interaction only if both main effects present in model.
method = "d", # method "d" means trial run, to get size of problem. Set to "h" for exhaustive search, or "g" for genetic algorithm
confsetsize = 1000, # how many models should glmulti() return? Must be less than total size of problem
plotty = FALSE, # provide progress plots? Generally annoying.
report = TRUE, # provide progress reports? Generally useful.
fitfunction = lm, # use lm() as fit function. Can also use glm() for logistic regression.
crit = aic # criterion for selecting best models.
)
glmulti_fit <- glmulti(
quality2 ~ ., # model to fit, in this case, charges varies with everything
level = 1, # level = 2 means try pairwise interactions. level = 1 means main effects only
data = train_automated, # data to use for fitting
minsize = 0, # min size of model to try, in number of predictors
maxsize = 10, # max size to try, set to -1 for unlimited
marginality = TRUE, # marginality true means include pairwise interaction only if both main effects present in model.
method = "d", # method "d" means trial run, to get size of problem. Set to "h" for exhaustive search, or "g" for genetic algorithm
confsetsize = 100, # how many models should glmulti() return? Must be less than total size of problem
plotty = FALSE, # provide progress plots? Generally annoying.
report = TRUE, # provide progress reports? Generally useful.
fitfunction = lm, # use lm() as fit function. Can also use glm() for logistic regression.
crit = aic # criterion for selecting best models.
)
glmulti_fit <- glmulti(
quality2 ~ .,
level = 1,
data = train_automated,
minsize = 0,
maxsize = 10,
marginality = TRUE,
method = "h",
confsetsize = 1000,
plotty = FALSE,
report = TRUE,
fitfunction = lm,
crit = aic
)
rmse_results <- numeric(1000)
for (i in 1:1000){
this_model <- glmulti_fit@objects[[i]]
predictions <- predict(this_model, newdata = test)
rmse_results[i] <- sqrt(mean((predictions - test$quality2)^2))
}
plot(rmse_results)
neg_r2 <- function(model){
sum_model <- summary(model)
return( -1 * sum_model$r.squared)
}
# save each glmulti_fit object to a list as we go
best_fits <- list()
# search out to models with 10 predictors
num_pred_max <- 10
for (num_pred in 1:num_pred_max){
# track progress
print(paste("num_pred =", num_pred))
# run the search for models of num_pred size
glmulti_fit <- glmulti(
quality2 ~ .,
level = 1,
data = train_automated,
minsize = num_pred, # only models of num_pred size
maxsize = num_pred, # only models of num_pred size
marginality = TRUE,
method = "h",
confsetsize = 1, # save only best model from this search
plotty = FALSE,
report = FALSE,
fitfunction = lm,
crit = neg_r2 # our custom crit function
)
best_fits <- append(best_fits, glmulti_fit)
}
rmse_results <- numeric(num_pred_max)
for (i in 1:num_pred_max){
this_model <- best_fits[[i]]@objects[[1]]
predictions <- predict(this_model, newdata = test)
rmse_results[i] <- sqrt(mean((predictions - test_automated$quality2)^2))
}
plot(rmse_results)
glmulti_fit
glmulti_fit@objects[[1]]
glmulti_fit$formula
best_mod <- glmulti_fit@objects[[1]]
best_mod$terms
anova(mod7, best_mod)
glmulti_model <- lm(quality2 ~ fixed_acidity + volatile_acidity + residual_sugar +
chlorides + free_sulfur_dioxide + total_sulfur_dioxide +
density + p_h + sulphates + alcohol, train_automated)
AIC(glmulti_model, mod7)
summary(glmulti_model)
relaimpo::calc.relimp(glmulti_model, type = "lmg", rela = TRUE)
View(glmulti_model)
glmulti_model$formula
train_pred <- train %>%
add_predictions(mod7)
ggplot(train_pred, aes(quality2)) +
geom_density
ggplot(train_pred, aes(quality2)) +
geom_density()
ggplot(train_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred))
ggplot(train_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = red)
ggplot(train_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(train_pred, aes(quality2, pred)) +
geom_point()
ggplot(train_pred, aes(quality2, pred)) +
geom_point() +
abline(a = 1, b = 0)
ggplot(train_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(a = 1, b = 0)
ggplot(train_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(a = 1, b = 0, colour = "blue")
ggplot(train_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, colour = "blue")
glmulti_pred <- train_automated %>%
add_predictions(glmulti_model)
ggplot(train_automated, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
View(test_automated)
View(train_automated)
View(glmulti_pred)
glmulti_pred <- train_automated %>%
add_predictions(glmulti_model)
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(glmulti_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(a = 1, b = 0, colour = "blue")
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(train_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(glmulti_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(a = 1, b = 0, colour = "blue")
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(train_pred, aes(pred), colour = "blue")
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(train_pred, aes(pred, colour = "blue"))
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(train_pred, aes(pred))
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(aes(residual_sugar))
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(train_pred, aes(residual_sugar))
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red") +
geom_density(train_pred, aes(pred))
ggplot() +
geom_density(glmulti_pred, aes(quality2)) +
geom_density(glmulti_pred, aes(pred), colour = "red") +
geom_density(train_pred, aes(pred), colour = "blue")
ggplot() +
geom_density(glmulti_pred, aes(quality2))
ggplot() +
geom_density(glmulti_pred, aes(x = quality2)) +
geom_density(glmulti_pred, aes(pred), colour = "red") +
geom_density(train_pred, aes(pred), colour = "blue")
ggplot() +
geom_density(glmulti_pred, aes(x = quality2))
?geom_density
library(tidyverse)
library(GGally)
library(ggfortify)
library(modelr)
#library(relaimpo). don't load as masks select function
library(glmulti)
library(caret)
white <- read_csv("clean_data/white.csv") %>%
janitor::clean_names()
n_data <- nrow(white)
test_index <- sample(1:n_data, size = n_data*0.2)
test  <- slice(white, test_index)
train <- slice(white, -test_index)
rm(n_data, test_index)
skimr::skim(white)
glimpse(white)
white %>%
ggplot(aes(quality2)) +
geom_density()
white %>%
ggplot(aes(quality2)) +
geom_histogram(binwidth = 0.05)
ggcorr(train,
label = TRUE,
label_round = 2,
label_size = 3,
layout.exp = 0.5,
hjust = 0.8,
size = 3)
mod1 <- lm(quality2 ~ alcohol, data = train)
summary(mod1)
#autoplot(mod1)
train_resid <- train %>%
add_residuals(mod1) %>%
select(-alcohol, -quality, -quality2)
#ggpairs(train_resid, progress = FALSE)
mod2 <- lm(quality2 ~ alcohol + volatile_acidity, train)
summary(mod2)
#autoplot(mod2)
train_resid <- train %>%
add_residuals(mod2) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity)
#ggpairs(train_resid, progress = FALSE)
mod3 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar, train)
summary(mod3)
#autoplot(mod3)
anova(mod3, mod2)
train_resid <- train %>%
add_residuals(mod3) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar)
#ggpairs(train_resid, progress = FALSE)
mod4 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide, train)
summary(mod4)
anova(mod3, mod4)
train_resid <- train %>%
add_residuals(mod4) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide)
#ggpairs(train_resid, progress = FALSE)
mod5 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity, train)
summary(mod5)
AIC(mod3, mod4, mod5)
BIC(mod3, mod4, mod5)
train_resid <- train %>%
add_residuals(mod5) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide, -fixed_acidity)
#ggpairs(train_resid, progress = FALSE)
mod6 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity + sulphates, train)
summary(mod6)
AIC(mod5, mod6)
BIC(mod5, mod6)
train_resid <- train %>%
add_residuals(mod6) %>%
select(-alcohol, -quality, -quality2, -volatile_acidity, -residual_sugar,
-free_sulfur_dioxide, -fixed_acidity, -sulphates)
#ggpairs(train_resid, progress = FALSE)
#autoplot(mod6)
#plot(mod6)
train %>%
ggplot(aes(quality2, sulphates, colour = residual_sugar)) +
geom_point() +
geom_smooth(method = "lm")
coplot(quality2 ~ residual_sugar | sulphates,
overlap = FALSE,
panel = function(x, y, ...){
points(x, y)
abline(lm(y ~ x), col = "blue")
},
data = train, rows = 1)
train %>%
ggplot(aes(x = quality2, y = alcohol, colour = region)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
mod7 <- lm(quality2 ~ alcohol + volatile_acidity + residual_sugar +
free_sulfur_dioxide + fixed_acidity + sulphates +
residual_sugar : volatile_acidity, train)
summary(mod7)
anova(mod6, mod7)
prediction <- predict(mod7, test)
output <- cbind(test, prediction)
output %>%
ggplot(aes(quality2, prediction)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, colour = "red")
relaimpo::calc.relimp(mod7, type = "lmg", rela = TRUE)
predictions_test <- test %>%
add_predictions(mod7) %>%
select(quality2, pred)
mse_test <- mean((predictions_test$pred - test$quality2)**2)
mse_test
predictions_train <- train %>%
add_predictions(mod7) %>%
select(quality2, pred)
mse_train <- mean((predictions_train$pred - train$quality2)**2)
mse_train
# remove quality and region variables before fitting glmulti
white_trim <- white %>%
select(-quality, -region)
train_index <- createDataPartition(white_trim$quality2, p = 0.8, list = FALSE, times = 1)
train_automated <- white_trim[train_index, ]
test_automated <- white_trim[-train_index,]
glmulti_fit <- glmulti(
quality2 ~ ., # model to fit, in this case, charges varies with everything
level = 2, # level = 2 means try pairwise interactions. level = 1 means main effects only
data = train_automated, # data to use for fitting
minsize = 0, # min size of model to try, in number of predictors
maxsize = -1, # max size to try, set to -1 for unlimited
marginality = TRUE, # marginality true means include pairwise interaction only if both main effects present in model.
method = "d", # method "d" means trial run, to get size of problem. Set to "h" for exhaustive search, or "g" for genetic algorithm
confsetsize = 1000, # how many models should glmulti() return? Must be less than total size of problem
plotty = FALSE, # provide progress plots? Generally annoying.
report = TRUE, # provide progress reports? Generally useful.
fitfunction = lm, # use lm() as fit function. Can also use glm() for logistic regression.
crit = aic # criterion for selecting best models.
)
glmulti_fit <- glmulti(
quality2 ~ ., # model to fit, in this case, charges varies with everything
level = 1, # level = 2 means try pairwise interactions. level = 1 means main effects only
data = train_automated, # data to use for fitting
minsize = 0, # min size of model to try, in number of predictors
maxsize = 10, # max size to try, set to -1 for unlimited
marginality = TRUE, # marginality true means include pairwise interaction only if both main effects present in model.
method = "d", # method "d" means trial run, to get size of problem. Set to "h" for exhaustive search, or "g" for genetic algorithm
confsetsize = 100, # how many models should glmulti() return? Must be less than total size of problem
plotty = FALSE, # provide progress plots? Generally annoying.
report = TRUE, # provide progress reports? Generally useful.
fitfunction = lm, # use lm() as fit function. Can also use glm() for logistic regression.
crit = aic # criterion for selecting best models.
)
glmulti_fit <- glmulti(
quality2 ~ .,
level = 1,
data = train_automated,
minsize = 0,
maxsize = 10,
marginality = TRUE,
method = "h",
confsetsize = 1000,
plotty = FALSE,
report = TRUE,
fitfunction = lm,
crit = aic
)
rmse_results <- numeric(1000)
for (i in 1:1000){
this_model <- glmulti_fit@objects[[i]]
predictions <- predict(this_model, newdata = test)
rmse_results[i] <- sqrt(mean((predictions - test$quality2)^2))
}
plot(rmse_results)
neg_r2 <- function(model){
sum_model <- summary(model)
return( -1 * sum_model$r.squared)
}
# save each glmulti_fit object to a list as we go
best_fits <- list()
# search out to models with 10 predictors
num_pred_max <- 10
for (num_pred in 1:num_pred_max){
# track progress
print(paste("num_pred =", num_pred))
# run the search for models of num_pred size
glmulti_fit <- glmulti(
quality2 ~ .,
level = 1,
data = train_automated,
minsize = num_pred, # only models of num_pred size
maxsize = num_pred, # only models of num_pred size
marginality = TRUE,
method = "h",
confsetsize = 1, # save only best model from this search
plotty = FALSE,
report = FALSE,
fitfunction = lm,
crit = neg_r2 # our custom crit function
)
best_fits <- append(best_fits, glmulti_fit)
}
rmse_results <- numeric(num_pred_max)
for (i in 1:num_pred_max){
this_model <- best_fits[[i]]@objects[[1]]
predictions <- predict(this_model, newdata = test)
rmse_results[i] <- sqrt(mean((predictions - test_automated$quality2)^2))
}
plot(rmse_results)
glmulti_fit
glmulti_fit@objects[[1]]
#glmulti_model$formula
#glmulti_model$formula
best_mod <- glmulti_fit@objects[[1]]
best_mod$terms
anova(mod7, best_mod)
glmulti_model <- lm(quality2 ~ fixed_acidity + volatile_acidity + residual_sugar +
chlorides + free_sulfur_dioxide + total_sulfur_dioxide +
density + p_h + sulphates + alcohol, train_automated)
AIC(glmulti_model, mod7)
summary(glmulti_model)
relaimpo::calc.relimp(glmulti_model, type = "lmg", rela = TRUE)
train_pred <- train %>%
add_predictions(mod7)
ggplot(train_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(train_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, colour = "blue")
glmulti_pred <- train_automated %>%
add_predictions(glmulti_model)
ggplot(glmulti_pred, aes(quality2)) +
geom_density() +
geom_density(aes(pred), colour = "red")
ggplot(glmulti_pred, aes(quality2, pred)) +
geom_point() +
geom_abline(a = 1, b = 0, colour = "blue")
ggplot() +
geom_density(glmulti_pred, aes(x = quality2)) +
geom_density(glmulti_pred, aes(pred), colour = "red") +
geom_density(train_pred, aes(pred), colour = "blue")
